{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Credit Card Fraud Detection assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zur3x-xt534C"
      },
      "source": [
        "# Credit Card Fraud Detection::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUGuIewg534Z"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwm67Y33534b"
      },
      "source": [
        "# Description about dataset::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZDLJRf5534b"
      },
      "source": [
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
        "\n",
        "\n",
        "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQo-mHEP534d"
      },
      "source": [
        "# WORKFLOW :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sjY3kie534e"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Standardized the Input Variables. \n",
        "\n",
        "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "\n",
        "7.Train the Model with Epochs (100).\n",
        "\n",
        "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "9.Prediction should be > 92%\n",
        "10.Evaluation Step\n",
        "11Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBG2hldz534f"
      },
      "source": [
        "# Task::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMsdWS7e534g"
      },
      "source": [
        "## Identify fraudulent credit card transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNG6e4bQ534i"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LHev1IF534j"
      },
      "source": [
        "df = pd.read_csv('creditcard.csv')"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGr7AIuD534j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "e390aa78-9e0b-442b-9389-564c359e4ce6"
      },
      "source": [
        "df"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>4.356170</td>\n",
              "      <td>-1.593105</td>\n",
              "      <td>2.711941</td>\n",
              "      <td>-0.689256</td>\n",
              "      <td>4.626942</td>\n",
              "      <td>-0.924459</td>\n",
              "      <td>1.107641</td>\n",
              "      <td>1.991691</td>\n",
              "      <td>0.510632</td>\n",
              "      <td>-0.682920</td>\n",
              "      <td>1.475829</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>-0.975926</td>\n",
              "      <td>-0.150189</td>\n",
              "      <td>0.915802</td>\n",
              "      <td>1.214756</td>\n",
              "      <td>-0.675143</td>\n",
              "      <td>1.164931</td>\n",
              "      <td>-0.711757</td>\n",
              "      <td>-0.025693</td>\n",
              "      <td>-1.221179</td>\n",
              "      <td>-1.545556</td>\n",
              "      <td>0.059616</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>-0.484782</td>\n",
              "      <td>0.411614</td>\n",
              "      <td>0.063119</td>\n",
              "      <td>-0.183699</td>\n",
              "      <td>-0.510602</td>\n",
              "      <td>1.329284</td>\n",
              "      <td>0.140716</td>\n",
              "      <td>0.313502</td>\n",
              "      <td>0.395652</td>\n",
              "      <td>-0.577252</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>-0.399126</td>\n",
              "      <td>-1.933849</td>\n",
              "      <td>-0.962886</td>\n",
              "      <td>-1.042082</td>\n",
              "      <td>0.449624</td>\n",
              "      <td>1.962563</td>\n",
              "      <td>-0.608577</td>\n",
              "      <td>0.509928</td>\n",
              "      <td>1.113981</td>\n",
              "      <td>2.897849</td>\n",
              "      <td>0.127434</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>-0.915427</td>\n",
              "      <td>-1.040458</td>\n",
              "      <td>-0.031513</td>\n",
              "      <td>-0.188093</td>\n",
              "      <td>-0.084316</td>\n",
              "      <td>0.041333</td>\n",
              "      <td>-0.302620</td>\n",
              "      <td>-0.660377</td>\n",
              "      <td>0.167430</td>\n",
              "      <td>-0.256117</td>\n",
              "      <td>0.382948</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time         V1         V2  ...       V28  Amount  Class\n",
              "0            0.0  -1.359807  -0.072781  ... -0.021053  149.62      0\n",
              "1            0.0   1.191857   0.266151  ...  0.014724    2.69      0\n",
              "2            1.0  -1.358354  -1.340163  ... -0.059752  378.66      0\n",
              "3            1.0  -0.966272  -0.185226  ...  0.061458  123.50      0\n",
              "4            2.0  -1.158233   0.877737  ...  0.215153   69.99      0\n",
              "...          ...        ...        ...  ...       ...     ...    ...\n",
              "284802  172786.0 -11.881118  10.071785  ...  0.823731    0.77      0\n",
              "284803  172787.0  -0.732789  -0.055080  ... -0.053527   24.79      0\n",
              "284804  172788.0   1.919565  -0.301254  ... -0.026561   67.88      0\n",
              "284805  172788.0  -0.240440   0.530483  ...  0.104533   10.00      0\n",
              "284806  172792.0  -0.533413  -0.189733  ...  0.013649  217.00      0\n",
              "\n",
              "[284807 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6zIKKT0534k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df18a775-310c-4477-ab30-df677ccede3f"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO74EMrP534k"
      },
      "source": [
        "df=df.fillna(df.mean())"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-iP-hIk534l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe8ba7e-e88e-49a0-83ed-c5868b0ec212"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p38c31It534m"
      },
      "source": [
        "op_labels= df.pop('Class')"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIJEInD6534n"
      },
      "source": [
        "mean = df.mean(axis=0)\n",
        "df-=mean\n",
        "std = df.std(axis=0)\n",
        "df/=std\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cFXkoKx534p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "2f8ef787-6166-4bd4-b945-d7815ecd919e"
      },
      "source": [
        "df"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.996580</td>\n",
              "      <td>-0.694241</td>\n",
              "      <td>-0.044075</td>\n",
              "      <td>1.672771</td>\n",
              "      <td>0.973364</td>\n",
              "      <td>-0.245116</td>\n",
              "      <td>0.347067</td>\n",
              "      <td>0.193679</td>\n",
              "      <td>0.082637</td>\n",
              "      <td>0.331127</td>\n",
              "      <td>0.083385</td>\n",
              "      <td>-0.540406</td>\n",
              "      <td>-0.618295</td>\n",
              "      <td>-0.996097</td>\n",
              "      <td>-0.324610</td>\n",
              "      <td>1.604011</td>\n",
              "      <td>-0.536832</td>\n",
              "      <td>0.244863</td>\n",
              "      <td>0.030770</td>\n",
              "      <td>0.496281</td>\n",
              "      <td>0.326117</td>\n",
              "      <td>-0.024923</td>\n",
              "      <td>0.382854</td>\n",
              "      <td>-0.176911</td>\n",
              "      <td>0.110507</td>\n",
              "      <td>0.246585</td>\n",
              "      <td>-0.392170</td>\n",
              "      <td>0.330891</td>\n",
              "      <td>-0.063781</td>\n",
              "      <td>0.244964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.996580</td>\n",
              "      <td>0.608495</td>\n",
              "      <td>0.161176</td>\n",
              "      <td>0.109797</td>\n",
              "      <td>0.316522</td>\n",
              "      <td>0.043483</td>\n",
              "      <td>-0.061820</td>\n",
              "      <td>-0.063700</td>\n",
              "      <td>0.071253</td>\n",
              "      <td>-0.232494</td>\n",
              "      <td>-0.153349</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.066087</td>\n",
              "      <td>0.491417</td>\n",
              "      <td>-0.149982</td>\n",
              "      <td>0.694359</td>\n",
              "      <td>0.529433</td>\n",
              "      <td>-0.135170</td>\n",
              "      <td>-0.218762</td>\n",
              "      <td>-0.179086</td>\n",
              "      <td>-0.089611</td>\n",
              "      <td>-0.307376</td>\n",
              "      <td>-0.880075</td>\n",
              "      <td>0.162201</td>\n",
              "      <td>-0.561130</td>\n",
              "      <td>0.320693</td>\n",
              "      <td>0.261069</td>\n",
              "      <td>-0.022256</td>\n",
              "      <td>0.044607</td>\n",
              "      <td>-0.342474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.996558</td>\n",
              "      <td>-0.693499</td>\n",
              "      <td>-0.811576</td>\n",
              "      <td>1.169466</td>\n",
              "      <td>0.268231</td>\n",
              "      <td>-0.364571</td>\n",
              "      <td>1.351451</td>\n",
              "      <td>0.639775</td>\n",
              "      <td>0.207372</td>\n",
              "      <td>-1.378673</td>\n",
              "      <td>0.190699</td>\n",
              "      <td>0.611829</td>\n",
              "      <td>0.066137</td>\n",
              "      <td>0.720699</td>\n",
              "      <td>-0.173114</td>\n",
              "      <td>2.562902</td>\n",
              "      <td>-3.298230</td>\n",
              "      <td>1.306866</td>\n",
              "      <td>-0.144790</td>\n",
              "      <td>-2.778556</td>\n",
              "      <td>0.680974</td>\n",
              "      <td>0.337631</td>\n",
              "      <td>1.063356</td>\n",
              "      <td>1.456317</td>\n",
              "      <td>-1.138090</td>\n",
              "      <td>-0.628536</td>\n",
              "      <td>-0.288446</td>\n",
              "      <td>-0.137137</td>\n",
              "      <td>-0.181021</td>\n",
              "      <td>1.160684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.996558</td>\n",
              "      <td>-0.493324</td>\n",
              "      <td>-0.112169</td>\n",
              "      <td>1.182514</td>\n",
              "      <td>-0.609726</td>\n",
              "      <td>-0.007469</td>\n",
              "      <td>0.936148</td>\n",
              "      <td>0.192070</td>\n",
              "      <td>0.316017</td>\n",
              "      <td>-1.262501</td>\n",
              "      <td>-0.050468</td>\n",
              "      <td>-0.221891</td>\n",
              "      <td>0.178371</td>\n",
              "      <td>0.510168</td>\n",
              "      <td>-0.300360</td>\n",
              "      <td>-0.689836</td>\n",
              "      <td>-1.209294</td>\n",
              "      <td>-0.805443</td>\n",
              "      <td>2.345300</td>\n",
              "      <td>-1.514202</td>\n",
              "      <td>-0.269855</td>\n",
              "      <td>-0.147443</td>\n",
              "      <td>0.007267</td>\n",
              "      <td>-0.304776</td>\n",
              "      <td>-1.941024</td>\n",
              "      <td>1.241902</td>\n",
              "      <td>-0.460217</td>\n",
              "      <td>0.155396</td>\n",
              "      <td>0.186188</td>\n",
              "      <td>0.140534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.996537</td>\n",
              "      <td>-0.591329</td>\n",
              "      <td>0.531540</td>\n",
              "      <td>1.021410</td>\n",
              "      <td>0.284655</td>\n",
              "      <td>-0.295015</td>\n",
              "      <td>0.071998</td>\n",
              "      <td>0.479301</td>\n",
              "      <td>-0.226510</td>\n",
              "      <td>0.744325</td>\n",
              "      <td>0.691624</td>\n",
              "      <td>-0.806145</td>\n",
              "      <td>0.538626</td>\n",
              "      <td>1.352242</td>\n",
              "      <td>-1.168031</td>\n",
              "      <td>0.191323</td>\n",
              "      <td>-0.515204</td>\n",
              "      <td>-0.279080</td>\n",
              "      <td>-0.045569</td>\n",
              "      <td>0.987036</td>\n",
              "      <td>0.529938</td>\n",
              "      <td>-0.012839</td>\n",
              "      <td>1.100009</td>\n",
              "      <td>-0.220123</td>\n",
              "      <td>0.233250</td>\n",
              "      <td>-0.395201</td>\n",
              "      <td>1.041609</td>\n",
              "      <td>0.543619</td>\n",
              "      <td>0.651815</td>\n",
              "      <td>-0.073403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>1.641929</td>\n",
              "      <td>-6.065831</td>\n",
              "      <td>6.099275</td>\n",
              "      <td>-6.486233</td>\n",
              "      <td>-1.459638</td>\n",
              "      <td>-3.886604</td>\n",
              "      <td>-1.956687</td>\n",
              "      <td>-3.975621</td>\n",
              "      <td>6.116562</td>\n",
              "      <td>1.742556</td>\n",
              "      <td>4.000708</td>\n",
              "      <td>-1.560777</td>\n",
              "      <td>2.714108</td>\n",
              "      <td>-0.692528</td>\n",
              "      <td>4.826792</td>\n",
              "      <td>-1.009989</td>\n",
              "      <td>1.264065</td>\n",
              "      <td>2.344995</td>\n",
              "      <td>0.609218</td>\n",
              "      <td>-0.838926</td>\n",
              "      <td>1.914361</td>\n",
              "      <td>0.290602</td>\n",
              "      <td>0.154146</td>\n",
              "      <td>1.624571</td>\n",
              "      <td>-0.840999</td>\n",
              "      <td>2.756316</td>\n",
              "      <td>0.518499</td>\n",
              "      <td>2.337897</td>\n",
              "      <td>2.495525</td>\n",
              "      <td>-0.350150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>1.641950</td>\n",
              "      <td>-0.374121</td>\n",
              "      <td>-0.033356</td>\n",
              "      <td>1.342142</td>\n",
              "      <td>-0.521651</td>\n",
              "      <td>0.629039</td>\n",
              "      <td>0.794444</td>\n",
              "      <td>0.019667</td>\n",
              "      <td>0.246886</td>\n",
              "      <td>0.532298</td>\n",
              "      <td>-0.896291</td>\n",
              "      <td>-0.147141</td>\n",
              "      <td>0.916534</td>\n",
              "      <td>1.220524</td>\n",
              "      <td>-0.704304</td>\n",
              "      <td>1.272709</td>\n",
              "      <td>-0.812274</td>\n",
              "      <td>-0.030250</td>\n",
              "      <td>-1.456948</td>\n",
              "      <td>-1.898623</td>\n",
              "      <td>0.077330</td>\n",
              "      <td>0.291625</td>\n",
              "      <td>1.273779</td>\n",
              "      <td>0.019958</td>\n",
              "      <td>-1.677917</td>\n",
              "      <td>-1.163724</td>\n",
              "      <td>-0.819645</td>\n",
              "      <td>0.169641</td>\n",
              "      <td>-0.162163</td>\n",
              "      <td>-0.254116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>1.641971</td>\n",
              "      <td>0.980022</td>\n",
              "      <td>-0.182433</td>\n",
              "      <td>-2.143201</td>\n",
              "      <td>-0.393983</td>\n",
              "      <td>1.905830</td>\n",
              "      <td>2.275258</td>\n",
              "      <td>-0.239939</td>\n",
              "      <td>0.593139</td>\n",
              "      <td>0.393630</td>\n",
              "      <td>-0.445224</td>\n",
              "      <td>0.403261</td>\n",
              "      <td>0.063169</td>\n",
              "      <td>-0.184571</td>\n",
              "      <td>-0.532656</td>\n",
              "      <td>1.452267</td>\n",
              "      <td>0.160588</td>\n",
              "      <td>0.369114</td>\n",
              "      <td>0.472040</td>\n",
              "      <td>-0.709119</td>\n",
              "      <td>0.001811</td>\n",
              "      <td>0.315912</td>\n",
              "      <td>0.796786</td>\n",
              "      <td>-0.060053</td>\n",
              "      <td>1.056942</td>\n",
              "      <td>0.509796</td>\n",
              "      <td>-0.181181</td>\n",
              "      <td>0.011037</td>\n",
              "      <td>-0.080467</td>\n",
              "      <td>-0.081839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>1.641971</td>\n",
              "      <td>-0.122755</td>\n",
              "      <td>0.321250</td>\n",
              "      <td>0.463319</td>\n",
              "      <td>0.487192</td>\n",
              "      <td>-0.273836</td>\n",
              "      <td>0.468154</td>\n",
              "      <td>-0.554671</td>\n",
              "      <td>0.568630</td>\n",
              "      <td>0.356886</td>\n",
              "      <td>-0.366557</td>\n",
              "      <td>-1.894606</td>\n",
              "      <td>-0.963656</td>\n",
              "      <td>-1.047030</td>\n",
              "      <td>0.469045</td>\n",
              "      <td>2.144137</td>\n",
              "      <td>-0.694522</td>\n",
              "      <td>0.600384</td>\n",
              "      <td>1.329053</td>\n",
              "      <td>3.559834</td>\n",
              "      <td>0.165299</td>\n",
              "      <td>0.361111</td>\n",
              "      <td>1.102449</td>\n",
              "      <td>-0.261503</td>\n",
              "      <td>0.203427</td>\n",
              "      <td>-1.091853</td>\n",
              "      <td>1.133633</td>\n",
              "      <td>0.269604</td>\n",
              "      <td>0.316686</td>\n",
              "      <td>-0.313248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>1.642055</td>\n",
              "      <td>-0.272330</td>\n",
              "      <td>-0.114899</td>\n",
              "      <td>0.463865</td>\n",
              "      <td>-0.357569</td>\n",
              "      <td>-0.009089</td>\n",
              "      <td>-0.487601</td>\n",
              "      <td>1.274767</td>\n",
              "      <td>-0.347176</td>\n",
              "      <td>0.442532</td>\n",
              "      <td>-0.840728</td>\n",
              "      <td>-1.019345</td>\n",
              "      <td>-0.031538</td>\n",
              "      <td>-0.188986</td>\n",
              "      <td>-0.087958</td>\n",
              "      <td>0.045158</td>\n",
              "      <td>-0.345357</td>\n",
              "      <td>-0.777520</td>\n",
              "      <td>0.199755</td>\n",
              "      <td>-0.314624</td>\n",
              "      <td>0.496738</td>\n",
              "      <td>0.355410</td>\n",
              "      <td>0.886147</td>\n",
              "      <td>0.603364</td>\n",
              "      <td>0.014526</td>\n",
              "      <td>-0.908630</td>\n",
              "      <td>-1.696850</td>\n",
              "      <td>-0.005984</td>\n",
              "      <td>0.041350</td>\n",
              "      <td>0.514354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2  ...       V27       V28    Amount\n",
              "0      -1.996580 -0.694241 -0.044075  ...  0.330891 -0.063781  0.244964\n",
              "1      -1.996580  0.608495  0.161176  ... -0.022256  0.044607 -0.342474\n",
              "2      -1.996558 -0.693499 -0.811576  ... -0.137137 -0.181021  1.160684\n",
              "3      -1.996558 -0.493324 -0.112169  ...  0.155396  0.186188  0.140534\n",
              "4      -1.996537 -0.591329  0.531540  ...  0.543619  0.651815 -0.073403\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "284802  1.641929 -6.065831  6.099275  ...  2.337897  2.495525 -0.350150\n",
              "284803  1.641950 -0.374121 -0.033356  ...  0.169641 -0.162163 -0.254116\n",
              "284804  1.641971  0.980022 -0.182433  ...  0.011037 -0.080467 -0.081839\n",
              "284805  1.641971 -0.122755  0.321250  ...  0.269604  0.316686 -0.313248\n",
              "284806  1.642055 -0.272330 -0.114899  ... -0.005984  0.041350  0.514354\n",
              "\n",
              "[284807 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke0Bx5uH534q"
      },
      "source": [
        "total=len(df)\n",
        "train=int(total*0.50)\n",
        "remaining = total-train\n",
        "val = int(remaining*0.40)\n",
        "test = remaining-val"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCLJpUdG534s"
      },
      "source": [
        "train_data=df.iloc[:train]\n",
        "val_data = df.iloc[train:train+val]\n",
        "test_data = df.iloc[-test:]"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nICNj7n7NMfg",
        "outputId": "f91b1638-c552-47a0-efdc-2c0462984f0d"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_w37JSBJEno"
      },
      "source": [
        "train_label=op_labels.iloc[:train]\n",
        "val_label = op_labels.iloc[train:train + val]\n",
        "test_label=op_labels.iloc[-test:]"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EszxvQQx534t"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(28, activation='relu', input_shape=(142403,30)))\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(6, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBxfhfMPIGT3"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBaykVpNIME7",
        "outputId": "5131da22-bc92-489a-f357-721c302d32bf"
      },
      "source": [
        "history = model.fit(train_data,train_label,epochs=100,batch_size=1024, validation_data=(val_data, val_label))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 142403, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 142403, 30), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 142403, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 142403, 30), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
            "123/140 [=========================>....] - ETA: 0s - loss: 0.2844 - accuracy: 0.9960WARNING:tensorflow:Model was constructed with shape (None, 142403, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 142403, 30), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.2654 - accuracy: 0.9963 - val_loss: 0.0466 - val_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0248 - val_accuracy: 0.9980\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 0.0242 - val_accuracy: 0.9991\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0225 - val_accuracy: 0.9991\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0179 - val_accuracy: 0.9991\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0218 - val_accuracy: 0.9991\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0238 - val_accuracy: 0.9991\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0165 - val_accuracy: 0.9991\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0191 - val_accuracy: 0.9989\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0206 - val_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0205 - val_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0206 - val_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0206 - val_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0192 - val_accuracy: 0.9969\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0172 - val_accuracy: 0.9968\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0163 - val_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0165 - val_accuracy: 0.9969\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0166 - val_accuracy: 0.9965\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0200 - val_accuracy: 0.9955\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0215 - val_accuracy: 0.9944\n",
            "Epoch 21/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
            "Epoch 22/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
            "Epoch 23/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0182 - val_accuracy: 0.9945\n",
            "Epoch 24/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0166 - val_accuracy: 0.9957\n",
            "Epoch 25/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
            "Epoch 26/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0174 - val_accuracy: 0.9952\n",
            "Epoch 27/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0137 - val_accuracy: 0.9970\n",
            "Epoch 28/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0156 - val_accuracy: 0.9961\n",
            "Epoch 29/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0146 - val_accuracy: 0.9966\n",
            "Epoch 30/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0130 - val_accuracy: 0.9972\n",
            "Epoch 31/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0146 - val_accuracy: 0.9968\n",
            "Epoch 32/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0138 - val_accuracy: 0.9970\n",
            "Epoch 33/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0158 - val_accuracy: 0.9963\n",
            "Epoch 34/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0133 - val_accuracy: 0.9974\n",
            "Epoch 35/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
            "Epoch 36/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0125 - val_accuracy: 0.9979\n",
            "Epoch 37/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0161 - val_accuracy: 0.9966\n",
            "Epoch 38/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0150 - val_accuracy: 0.9969\n",
            "Epoch 39/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0138 - val_accuracy: 0.9975\n",
            "Epoch 40/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0154 - val_accuracy: 0.9972\n",
            "Epoch 41/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0159 - val_accuracy: 0.9969\n",
            "Epoch 42/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0163 - val_accuracy: 0.9972\n",
            "Epoch 43/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0169 - val_accuracy: 0.9969\n",
            "Epoch 44/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0163 - val_accuracy: 0.9974\n",
            "Epoch 45/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0158 - val_accuracy: 0.9978\n",
            "Epoch 46/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0176 - val_accuracy: 0.9975\n",
            "Epoch 47/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0179 - val_accuracy: 0.9974\n",
            "Epoch 48/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0185 - val_accuracy: 0.9972\n",
            "Epoch 49/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0186 - val_accuracy: 0.9972\n",
            "Epoch 50/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0205 - val_accuracy: 0.9967\n",
            "Epoch 51/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0232 - val_accuracy: 0.9961\n",
            "Epoch 52/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0213 - val_accuracy: 0.9968\n",
            "Epoch 53/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0224 - val_accuracy: 0.9968\n",
            "Epoch 54/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0234 - val_accuracy: 0.9963\n",
            "Epoch 55/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0236 - val_accuracy: 0.9963\n",
            "Epoch 56/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0290 - val_accuracy: 0.9946\n",
            "Epoch 57/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0291 - val_accuracy: 0.9943\n",
            "Epoch 58/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0308 - val_accuracy: 0.9944\n",
            "Epoch 59/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0298 - val_accuracy: 0.9945\n",
            "Epoch 60/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0317 - val_accuracy: 0.9944\n",
            "Epoch 61/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.2239e-04 - accuracy: 0.9997 - val_loss: 0.0290 - val_accuracy: 0.9952\n",
            "Epoch 62/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 9.8854e-04 - accuracy: 0.9996 - val_loss: 0.0343 - val_accuracy: 0.9934\n",
            "Epoch 63/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 8.0879e-04 - accuracy: 0.9997 - val_loss: 0.0311 - val_accuracy: 0.9944\n",
            "Epoch 64/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0425 - val_accuracy: 0.9910\n",
            "Epoch 65/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.1571e-04 - accuracy: 0.9997 - val_loss: 0.0373 - val_accuracy: 0.9928\n",
            "Epoch 66/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0414 - val_accuracy: 0.9920\n",
            "Epoch 67/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.5152e-04 - accuracy: 0.9997 - val_loss: 0.0505 - val_accuracy: 0.9892\n",
            "Epoch 68/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.6939e-04 - accuracy: 0.9997 - val_loss: 0.0436 - val_accuracy: 0.9913\n",
            "Epoch 69/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 9.6832e-04 - accuracy: 0.9996 - val_loss: 0.0513 - val_accuracy: 0.9887\n",
            "Epoch 70/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.4558e-04 - accuracy: 0.9996 - val_loss: 0.0488 - val_accuracy: 0.9894\n",
            "Epoch 71/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.9408e-04 - accuracy: 0.9997 - val_loss: 0.0517 - val_accuracy: 0.9889\n",
            "Epoch 72/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 8.0338e-04 - accuracy: 0.9999 - val_loss: 0.0520 - val_accuracy: 0.9887\n",
            "Epoch 73/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 8.7212e-04 - accuracy: 0.9999 - val_loss: 0.0571 - val_accuracy: 0.9867\n",
            "Epoch 74/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 8.3557e-04 - accuracy: 0.9999 - val_loss: 0.0561 - val_accuracy: 0.9885\n",
            "Epoch 75/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.0807e-04 - accuracy: 0.9999 - val_loss: 0.0490 - val_accuracy: 0.9901\n",
            "Epoch 76/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.6522e-04 - accuracy: 0.9998 - val_loss: 0.0563 - val_accuracy: 0.9883\n",
            "Epoch 77/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.6001e-04 - accuracy: 0.9999 - val_loss: 0.0535 - val_accuracy: 0.9889\n",
            "Epoch 78/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.9097e-04 - accuracy: 0.9999 - val_loss: 0.0547 - val_accuracy: 0.9884\n",
            "Epoch 79/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.3992e-04 - accuracy: 0.9999 - val_loss: 0.0616 - val_accuracy: 0.9864\n",
            "Epoch 80/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.4983e-04 - accuracy: 0.9999 - val_loss: 0.0733 - val_accuracy: 0.9825\n",
            "Epoch 81/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.9553e-04 - accuracy: 0.9999 - val_loss: 0.0770 - val_accuracy: 0.9810\n",
            "Epoch 82/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.0456e-04 - accuracy: 0.9998 - val_loss: 0.0635 - val_accuracy: 0.9851\n",
            "Epoch 83/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.6429e-04 - accuracy: 0.9998 - val_loss: 0.0822 - val_accuracy: 0.9803\n",
            "Epoch 84/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.5523e-04 - accuracy: 0.9999 - val_loss: 0.0660 - val_accuracy: 0.9854\n",
            "Epoch 85/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.2396e-04 - accuracy: 0.9999 - val_loss: 0.0700 - val_accuracy: 0.9837\n",
            "Epoch 86/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.1348e-04 - accuracy: 0.9998 - val_loss: 0.0873 - val_accuracy: 0.9795\n",
            "Epoch 87/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.9432e-04 - accuracy: 0.9999 - val_loss: 0.0731 - val_accuracy: 0.9822\n",
            "Epoch 88/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.2218e-04 - accuracy: 0.9999 - val_loss: 0.0706 - val_accuracy: 0.9843\n",
            "Epoch 89/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.8554e-04 - accuracy: 0.9999 - val_loss: 0.0823 - val_accuracy: 0.9805\n",
            "Epoch 90/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.3494e-04 - accuracy: 0.9999 - val_loss: 0.0680 - val_accuracy: 0.9850\n",
            "Epoch 91/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.8598e-04 - accuracy: 0.9999 - val_loss: 0.0767 - val_accuracy: 0.9823\n",
            "Epoch 92/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.8089e-04 - accuracy: 0.9999 - val_loss: 0.0812 - val_accuracy: 0.9815\n",
            "Epoch 93/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.6941e-04 - accuracy: 0.9999 - val_loss: 0.0784 - val_accuracy: 0.9817\n",
            "Epoch 94/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.5012e-04 - accuracy: 0.9999 - val_loss: 0.0826 - val_accuracy: 0.9799\n",
            "Epoch 95/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.0257e-04 - accuracy: 0.9999 - val_loss: 0.0950 - val_accuracy: 0.9761\n",
            "Epoch 96/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.0055e-04 - accuracy: 0.9999 - val_loss: 0.0843 - val_accuracy: 0.9797\n",
            "Epoch 97/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.3179e-04 - accuracy: 0.9999 - val_loss: 0.0985 - val_accuracy: 0.9764\n",
            "Epoch 98/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.6500e-04 - accuracy: 0.9999 - val_loss: 0.0983 - val_accuracy: 0.9765\n",
            "Epoch 99/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.2538e-04 - accuracy: 0.9999 - val_loss: 0.1234 - val_accuracy: 0.9699\n",
            "Epoch 100/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.3703e-04 - accuracy: 0.9999 - val_loss: 0.1004 - val_accuracy: 0.9749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX9VDpqIKANq",
        "outputId": "52321632-2186-4a68-ec62-6e2d2b35a505"
      },
      "source": [
        "results = model.evaluate(test_data, test_label)\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2671/2671 [==============================] - 3s 1ms/step - loss: 0.0901 - accuracy: 0.9717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSS6FtlS2em",
        "outputId": "53a0f025-314c-46eb-cc51-09e4d872aa5d"
      },
      "source": [
        "model.predict(test_data)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 142403, 30) for input KerasTensor(type_spec=TensorSpec(shape=(None, 142403, 30), dtype=tf.float32, name='dense_60_input'), name='dense_60_input', description=\"created by layer 'dense_60_input'\"), but it was called on an input with incompatible shape (None, 30).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.4716948e-10],\n",
              "       [4.1465662e-09],\n",
              "       [3.4674451e-07],\n",
              "       ...,\n",
              "       [7.5402932e-07],\n",
              "       [4.7131865e-10],\n",
              "       [2.4013525e-07]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IGiD_vHTLHB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}