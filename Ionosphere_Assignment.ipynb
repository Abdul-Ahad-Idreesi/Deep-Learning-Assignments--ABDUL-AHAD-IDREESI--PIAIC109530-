{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of Ionosphere Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeJY2g251z7w"
      },
      "source": [
        "# Assignment: Ionosphere Data Problem\n",
        "\n",
        "### Dataset Description: \n",
        "\n",
        "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
        "\n",
        "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
        "\n",
        "### Attribute Information:\n",
        "\n",
        "- All 34 are continuous\n",
        "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
        "\n",
        " <br><br>\n",
        "\n",
        "<table border=\"1\"  cellpadding=\"6\">\n",
        "\t<tbody>\n",
        "        <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">351</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Physical</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
        "            <td><p class=\"normal\">Integer,Real</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
        "            <td><p class=\"normal\">34</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
        "            <td><p class=\"normal\">N/A</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\t\n",
        "    <tbody>\n",
        "    <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Classification</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t</tr>\n",
        "    </tbody>\n",
        "    </table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37LcQXH31z78"
      },
      "source": [
        "### WORKFLOW :\n",
        "- Load Data\n",
        "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
        "- Shuffle the data if needed.\n",
        "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
        "- Split into 60 and 40 ratio.\n",
        "- Encode labels.\n",
        "- Model : 1 hidden layers including 16 unit.\n",
        "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "- Train the Model with Epochs (100).\n",
        "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "- Prediction should be > **92%**\n",
        "- Evaluation Step\n",
        "- Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFRainBu1z79"
      },
      "source": [
        "# Load Data:\n",
        "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW5KmxLj1z7-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ZaDvRJ4vQ7"
      },
      "source": [
        "ds= pd.read_csv('ionosphere_data.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DP5wkAw5_FP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "84b44153-778c-41e0-acdd-c009a336fa28"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0         1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1         1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2         1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3         1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4         1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qxZJzDYcaa"
      },
      "source": [
        "label=ds.pop('label') "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVgmTC9qYsQr"
      },
      "source": [
        "label=np.where(label=='g', 1, 0) # encoding labels"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKUMdl1q7hBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d865fa3-853f-4c89-d465-3020b04a0c3c"
      },
      "source": [
        "ds.isnull().sum()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1     0\n",
              "feature2     0\n",
              "feature3     0\n",
              "feature4     0\n",
              "feature5     0\n",
              "feature6     0\n",
              "feature7     0\n",
              "feature8     0\n",
              "feature9     0\n",
              "feature10    0\n",
              "feature11    0\n",
              "feature12    0\n",
              "feature13    0\n",
              "feature14    0\n",
              "feature15    0\n",
              "feature16    0\n",
              "feature17    0\n",
              "feature18    0\n",
              "feature19    0\n",
              "feature20    0\n",
              "feature21    0\n",
              "feature22    0\n",
              "feature23    0\n",
              "feature24    0\n",
              "feature25    0\n",
              "feature26    0\n",
              "feature27    0\n",
              "feature28    0\n",
              "feature29    0\n",
              "feature30    0\n",
              "feature31    0\n",
              "feature32    0\n",
              "feature33    0\n",
              "feature34    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEH6P6jR-Ldb"
      },
      "source": [
        "mean = ds.mean(axis=0)\n",
        "ds -= mean\n",
        "std = ds.std(axis=0)\n",
        "ds /= std"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9tiE8ZXBIOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6a812fd9-75ae-4450-ec8d-d16f786d5735"
      },
      "source": [
        "ds.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.347937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.711357</td>\n",
              "      <td>-0.233923</td>\n",
              "      <td>0.483517</td>\n",
              "      <td>-0.201447</td>\n",
              "      <td>0.576236</td>\n",
              "      <td>-0.953318</td>\n",
              "      <td>0.962700</td>\n",
              "      <td>-0.297086</td>\n",
              "      <td>0.667701</td>\n",
              "      <td>-0.672148</td>\n",
              "      <td>0.316222</td>\n",
              "      <td>-1.096977</td>\n",
              "      <td>0.400107</td>\n",
              "      <td>-0.989074</td>\n",
              "      <td>0.746919</td>\n",
              "      <td>-0.768584</td>\n",
              "      <td>0.355648</td>\n",
              "      <td>-0.573895</td>\n",
              "      <td>0.382099</td>\n",
              "      <td>-0.588684</td>\n",
              "      <td>0.011568</td>\n",
              "      <td>-0.789002</td>\n",
              "      <td>0.297303</td>\n",
              "      <td>-0.866328</td>\n",
              "      <td>-0.253506</td>\n",
              "      <td>-0.712953</td>\n",
              "      <td>-0.287879</td>\n",
              "      <td>-0.616159</td>\n",
              "      <td>0.122762</td>\n",
              "      <td>-1.053550</td>\n",
              "      <td>-0.311776</td>\n",
              "      <td>-0.998170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.347937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.720619</td>\n",
              "      <td>-0.527058</td>\n",
              "      <td>0.633404</td>\n",
              "      <td>-1.036108</td>\n",
              "      <td>-1.337197</td>\n",
              "      <td>-2.026559</td>\n",
              "      <td>0.962700</td>\n",
              "      <td>-0.468813</td>\n",
              "      <td>0.057777</td>\n",
              "      <td>-1.682379</td>\n",
              "      <td>-0.090779</td>\n",
              "      <td>-1.597348</td>\n",
              "      <td>-1.318892</td>\n",
              "      <td>-2.282612</td>\n",
              "      <td>-0.529042</td>\n",
              "      <td>-1.245573</td>\n",
              "      <td>-0.045188</td>\n",
              "      <td>-1.880216</td>\n",
              "      <td>-0.767766</td>\n",
              "      <td>-0.890248</td>\n",
              "      <td>-0.899412</td>\n",
              "      <td>-0.568643</td>\n",
              "      <td>-1.036310</td>\n",
              "      <td>-0.382508</td>\n",
              "      <td>-1.445785</td>\n",
              "      <td>-0.208122</td>\n",
              "      <td>-0.987775</td>\n",
              "      <td>-0.173282</td>\n",
              "      <td>-0.907767</td>\n",
              "      <td>-0.115049</td>\n",
              "      <td>-0.931276</td>\n",
              "      <td>-0.083167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.347937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.720619</td>\n",
              "      <td>-0.176746</td>\n",
              "      <td>0.767382</td>\n",
              "      <td>-0.240965</td>\n",
              "      <td>0.913227</td>\n",
              "      <td>-0.460836</td>\n",
              "      <td>0.745075</td>\n",
              "      <td>-0.350036</td>\n",
              "      <td>0.451888</td>\n",
              "      <td>-0.205289</td>\n",
              "      <td>0.729089</td>\n",
              "      <td>-0.172052</td>\n",
              "      <td>0.309041</td>\n",
              "      <td>-0.148662</td>\n",
              "      <td>0.737518</td>\n",
              "      <td>-0.267378</td>\n",
              "      <td>0.632255</td>\n",
              "      <td>-0.118240</td>\n",
              "      <td>0.610294</td>\n",
              "      <td>-0.546767</td>\n",
              "      <td>0.118215</td>\n",
              "      <td>-0.119847</td>\n",
              "      <td>0.309698</td>\n",
              "      <td>-0.650967</td>\n",
              "      <td>0.093372</td>\n",
              "      <td>-0.276192</td>\n",
              "      <td>0.091259</td>\n",
              "      <td>-0.286910</td>\n",
              "      <td>0.440689</td>\n",
              "      <td>-0.463431</td>\n",
              "      <td>0.403867</td>\n",
              "      <td>-0.847381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.347937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.720619</td>\n",
              "      <td>-1.123568</td>\n",
              "      <td>0.767382</td>\n",
              "      <td>1.918601</td>\n",
              "      <td>0.328963</td>\n",
              "      <td>-2.149516</td>\n",
              "      <td>-1.009432</td>\n",
              "      <td>-0.374796</td>\n",
              "      <td>-0.845050</td>\n",
              "      <td>-0.313329</td>\n",
              "      <td>-0.644182</td>\n",
              "      <td>-0.188763</td>\n",
              "      <td>-2.058980</td>\n",
              "      <td>0.161502</td>\n",
              "      <td>0.257259</td>\n",
              "      <td>-0.784446</td>\n",
              "      <td>-2.170624</td>\n",
              "      <td>-1.003023</td>\n",
              "      <td>-1.699569</td>\n",
              "      <td>1.913874</td>\n",
              "      <td>-0.600356</td>\n",
              "      <td>0.108835</td>\n",
              "      <td>1.043935</td>\n",
              "      <td>1.923594</td>\n",
              "      <td>-0.049420</td>\n",
              "      <td>1.944525</td>\n",
              "      <td>1.079303</td>\n",
              "      <td>-0.340732</td>\n",
              "      <td>-0.167448</td>\n",
              "      <td>1.954525</td>\n",
              "      <td>-1.287987</td>\n",
              "      <td>2.104295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.347937</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.720619</td>\n",
              "      <td>-0.154908</td>\n",
              "      <td>0.654659</td>\n",
              "      <td>-0.109761</td>\n",
              "      <td>0.752993</td>\n",
              "      <td>-0.675776</td>\n",
              "      <td>0.512107</td>\n",
              "      <td>-0.713723</td>\n",
              "      <td>0.091921</td>\n",
              "      <td>-0.723076</td>\n",
              "      <td>0.262444</td>\n",
              "      <td>-0.203151</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.754198</td>\n",
              "      <td>0.238586</td>\n",
              "      <td>-0.431159</td>\n",
              "      <td>0.146392</td>\n",
              "      <td>-0.296884</td>\n",
              "      <td>-0.454022</td>\n",
              "      <td>-0.702566</td>\n",
              "      <td>-0.562113</td>\n",
              "      <td>-0.893693</td>\n",
              "      <td>-0.628013</td>\n",
              "      <td>-1.141395</td>\n",
              "      <td>-0.791819</td>\n",
              "      <td>-0.840911</td>\n",
              "      <td>-0.614940</td>\n",
              "      <td>-1.169475</td>\n",
              "      <td>-0.716703</td>\n",
              "      <td>-1.152581</td>\n",
              "      <td>-0.756593</td>\n",
              "      <td>-1.433689</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature32  feature33  feature34\n",
              "0  0.347937       NaN  0.711357  ...  -1.053550  -0.311776  -0.998170\n",
              "1  0.347937       NaN  0.720619  ...  -0.115049  -0.931276  -0.083167\n",
              "2  0.347937       NaN  0.720619  ...  -0.463431   0.403867  -0.847381\n",
              "3  0.347937       NaN  0.720619  ...   1.954525  -1.287987   2.104295\n",
              "4  0.347937       NaN  0.720619  ...  -1.152581  -0.756593  -1.433689\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9KrBIqMBFNT"
      },
      "source": [
        "ds.feature2 = 0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3B-6pWsB31W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5baef4-aed5-4c5a-defc-1d3a667d26b8"
      },
      "source": [
        "ds.isnull().sum()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1     0\n",
              "feature2     0\n",
              "feature3     0\n",
              "feature4     0\n",
              "feature5     0\n",
              "feature6     0\n",
              "feature7     0\n",
              "feature8     0\n",
              "feature9     0\n",
              "feature10    0\n",
              "feature11    0\n",
              "feature12    0\n",
              "feature13    0\n",
              "feature14    0\n",
              "feature15    0\n",
              "feature16    0\n",
              "feature17    0\n",
              "feature18    0\n",
              "feature19    0\n",
              "feature20    0\n",
              "feature21    0\n",
              "feature22    0\n",
              "feature23    0\n",
              "feature24    0\n",
              "feature25    0\n",
              "feature26    0\n",
              "feature27    0\n",
              "feature28    0\n",
              "feature29    0\n",
              "feature30    0\n",
              "feature31    0\n",
              "feature32    0\n",
              "feature33    0\n",
              "feature34    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cMpt9b6B1KI"
      },
      "source": [
        "total= len(ds)\n",
        "train= int (total *0.60)\n",
        "val = total-train\n",
        "val_split = int(val*0.5)\n",
        "test_split = val-val_split"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXUCo8tPT1BH"
      },
      "source": [
        "train_data=ds.iloc[:train]\n",
        "val_data = ds.iloc[train:train + val_split]\n",
        "test_data=ds.iloc[-test_split:]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlFbGv4tFaZy",
        "outputId": "84e77f1f-b337-4efe-9032-85023d5253d2"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwgUOxwpVrSY"
      },
      "source": [
        "train_label=label[:train]\n",
        "val_label = label[train:train + val_split]\n",
        "test_label=label[-test_split:]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk7_BSkxWQ1I"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(210,34)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ7VcDqPbjAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b76a8b1-9003-439d-ea4f-b55589cd117b"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(train_data, train_label, epochs=100, batch_size=64,validation_data=(val_data, val_label))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 210, 34) for input KerasTensor(type_spec=TensorSpec(shape=(None, 210, 34), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 34).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 210, 34) for input KerasTensor(type_spec=TensorSpec(shape=(None, 210, 34), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 34).\n",
            "1/4 [======>.......................] - ETA: 2s - loss: 0.9760 - acc: 0.3281WARNING:tensorflow:Model was constructed with shape (None, 210, 34) for input KerasTensor(type_spec=TensorSpec(shape=(None, 210, 34), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 34).\n",
            "4/4 [==============================] - 1s 95ms/step - loss: 0.9203 - acc: 0.3616 - val_loss: 0.7287 - val_acc: 0.4857\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.8312 - acc: 0.3812 - val_loss: 0.7056 - val_acc: 0.5143\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7588 - acc: 0.4783 - val_loss: 0.6883 - val_acc: 0.5714\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7184 - acc: 0.5831 - val_loss: 0.6743 - val_acc: 0.6000\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6906 - acc: 0.5963 - val_loss: 0.6583 - val_acc: 0.7143\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6925 - acc: 0.6295 - val_loss: 0.6471 - val_acc: 0.7000\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6532 - acc: 0.6814 - val_loss: 0.6358 - val_acc: 0.6714\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6154 - acc: 0.7132 - val_loss: 0.6275 - val_acc: 0.7000\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6028 - acc: 0.7206 - val_loss: 0.6145 - val_acc: 0.7286\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5728 - acc: 0.7702 - val_loss: 0.6085 - val_acc: 0.7429\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5624 - acc: 0.7603 - val_loss: 0.5987 - val_acc: 0.7571\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5360 - acc: 0.7721 - val_loss: 0.5879 - val_acc: 0.7571\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5305 - acc: 0.7686 - val_loss: 0.5783 - val_acc: 0.7714\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5225 - acc: 0.7804 - val_loss: 0.5667 - val_acc: 0.7714\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4995 - acc: 0.7943 - val_loss: 0.5526 - val_acc: 0.7857\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4800 - acc: 0.7943 - val_loss: 0.5437 - val_acc: 0.7857\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4797 - acc: 0.7740 - val_loss: 0.5335 - val_acc: 0.8000\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4472 - acc: 0.8275 - val_loss: 0.5275 - val_acc: 0.8000\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4280 - acc: 0.8398 - val_loss: 0.5162 - val_acc: 0.8286\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4361 - acc: 0.8358 - val_loss: 0.5059 - val_acc: 0.8286\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4336 - acc: 0.8387 - val_loss: 0.4956 - val_acc: 0.8429\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4057 - acc: 0.8448 - val_loss: 0.4832 - val_acc: 0.8429\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4073 - acc: 0.8621 - val_loss: 0.4764 - val_acc: 0.8429\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3866 - acc: 0.8552 - val_loss: 0.4724 - val_acc: 0.8429\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3691 - acc: 0.8767 - val_loss: 0.4598 - val_acc: 0.8429\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3817 - acc: 0.8696 - val_loss: 0.4515 - val_acc: 0.8571\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3463 - acc: 0.8914 - val_loss: 0.4445 - val_acc: 0.8571\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3387 - acc: 0.9051 - val_loss: 0.4356 - val_acc: 0.8429\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3413 - acc: 0.9006 - val_loss: 0.4235 - val_acc: 0.8429\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3195 - acc: 0.9053 - val_loss: 0.4090 - val_acc: 0.8571\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3323 - acc: 0.8879 - val_loss: 0.4028 - val_acc: 0.8571\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.3021 - acc: 0.9098 - val_loss: 0.3888 - val_acc: 0.8571\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2870 - acc: 0.9209 - val_loss: 0.3861 - val_acc: 0.8714\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2868 - acc: 0.9136 - val_loss: 0.3760 - val_acc: 0.8857\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2808 - acc: 0.9162 - val_loss: 0.3694 - val_acc: 0.8857\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2768 - acc: 0.9150 - val_loss: 0.3579 - val_acc: 0.8857\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2754 - acc: 0.9135 - val_loss: 0.3542 - val_acc: 0.8857\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2481 - acc: 0.9287 - val_loss: 0.3437 - val_acc: 0.8857\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2402 - acc: 0.9329 - val_loss: 0.3400 - val_acc: 0.8857\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2569 - acc: 0.9327 - val_loss: 0.3262 - val_acc: 0.8857\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2337 - acc: 0.9353 - val_loss: 0.3228 - val_acc: 0.8857\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2425 - acc: 0.9265 - val_loss: 0.3138 - val_acc: 0.8857\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2223 - acc: 0.9275 - val_loss: 0.3047 - val_acc: 0.8857\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2286 - acc: 0.9259 - val_loss: 0.2982 - val_acc: 0.9000\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2132 - acc: 0.9353 - val_loss: 0.2967 - val_acc: 0.9000\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2026 - acc: 0.9400 - val_loss: 0.2881 - val_acc: 0.9000\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1892 - acc: 0.9468 - val_loss: 0.2818 - val_acc: 0.9000\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2073 - acc: 0.9299 - val_loss: 0.2747 - val_acc: 0.9000\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1814 - acc: 0.9435 - val_loss: 0.2690 - val_acc: 0.9000\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1898 - acc: 0.9379 - val_loss: 0.2692 - val_acc: 0.9000\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2129 - acc: 0.9226 - val_loss: 0.2621 - val_acc: 0.9000\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1804 - acc: 0.9445 - val_loss: 0.2605 - val_acc: 0.9000\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1816 - acc: 0.9357 - val_loss: 0.2600 - val_acc: 0.9000\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1822 - acc: 0.9393 - val_loss: 0.2507 - val_acc: 0.9000\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1743 - acc: 0.9331 - val_loss: 0.2491 - val_acc: 0.9000\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1738 - acc: 0.9331 - val_loss: 0.2416 - val_acc: 0.9000\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1745 - acc: 0.9422 - val_loss: 0.2414 - val_acc: 0.9000\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1633 - acc: 0.9436 - val_loss: 0.2383 - val_acc: 0.8857\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1628 - acc: 0.9421 - val_loss: 0.2332 - val_acc: 0.8857\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1559 - acc: 0.9468 - val_loss: 0.2299 - val_acc: 0.9000\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1509 - acc: 0.9389 - val_loss: 0.2281 - val_acc: 0.9000\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1619 - acc: 0.9374 - val_loss: 0.2217 - val_acc: 0.9000\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1512 - acc: 0.9478 - val_loss: 0.2157 - val_acc: 0.9286\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1505 - acc: 0.9379 - val_loss: 0.2170 - val_acc: 0.9143\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1423 - acc: 0.9426 - val_loss: 0.2129 - val_acc: 0.9286\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1394 - acc: 0.9483 - val_loss: 0.2081 - val_acc: 0.9286\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1219 - acc: 0.9629 - val_loss: 0.2077 - val_acc: 0.9286\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1290 - acc: 0.9650 - val_loss: 0.2008 - val_acc: 0.9429\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1190 - acc: 0.9627 - val_loss: 0.2039 - val_acc: 0.9286\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1409 - acc: 0.9509 - val_loss: 0.2010 - val_acc: 0.9286\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1243 - acc: 0.9572 - val_loss: 0.2017 - val_acc: 0.9286\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1104 - acc: 0.9743 - val_loss: 0.2038 - val_acc: 0.9286\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1113 - acc: 0.9731 - val_loss: 0.1979 - val_acc: 0.9429\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1271 - acc: 0.9664 - val_loss: 0.1933 - val_acc: 0.9429\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1097 - acc: 0.9618 - val_loss: 0.1917 - val_acc: 0.9429\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1185 - acc: 0.9608 - val_loss: 0.1898 - val_acc: 0.9429\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1188 - acc: 0.9561 - val_loss: 0.1902 - val_acc: 0.9429\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1029 - acc: 0.9700 - val_loss: 0.1863 - val_acc: 0.9429\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1030 - acc: 0.9691 - val_loss: 0.1866 - val_acc: 0.9429\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1051 - acc: 0.9684 - val_loss: 0.1854 - val_acc: 0.9429\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1042 - acc: 0.9664 - val_loss: 0.1833 - val_acc: 0.9429\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0910 - acc: 0.9710 - val_loss: 0.1814 - val_acc: 0.9429\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1025 - acc: 0.9606 - val_loss: 0.1788 - val_acc: 0.9429\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0967 - acc: 0.9679 - val_loss: 0.1743 - val_acc: 0.9429\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0903 - acc: 0.9716 - val_loss: 0.1738 - val_acc: 0.9429\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0846 - acc: 0.9736 - val_loss: 0.1713 - val_acc: 0.9429\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0905 - acc: 0.9679 - val_loss: 0.1680 - val_acc: 0.9429\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0944 - acc: 0.9683 - val_loss: 0.1703 - val_acc: 0.9429\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0853 - acc: 0.9653 - val_loss: 0.1695 - val_acc: 0.9429\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0728 - acc: 0.9773 - val_loss: 0.1721 - val_acc: 0.9429\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0702 - acc: 0.9710 - val_loss: 0.1723 - val_acc: 0.9429\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0817 - acc: 0.9716 - val_loss: 0.1695 - val_acc: 0.9429\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0787 - acc: 0.9684 - val_loss: 0.1693 - val_acc: 0.9429\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0910 - acc: 0.9559 - val_loss: 0.1688 - val_acc: 0.9429\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0776 - acc: 0.9637 - val_loss: 0.1680 - val_acc: 0.9429\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0702 - acc: 0.9745 - val_loss: 0.1671 - val_acc: 0.9429\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0770 - acc: 0.9662 - val_loss: 0.1691 - val_acc: 0.9429\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0704 - acc: 0.9745 - val_loss: 0.1693 - val_acc: 0.9429\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0688 - acc: 0.9761 - val_loss: 0.1694 - val_acc: 0.9429\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0697 - acc: 0.9724 - val_loss: 0.1689 - val_acc: 0.9429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onC0aINPEsOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222563d4-a7ea-4838-b6d2-fe1e44138e76"
      },
      "source": [
        "results = model.evaluate(test_data, test_label)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0832 - acc: 0.9859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0TiqLTITmfR",
        "outputId": "7e0c89f0-e43f-46bd-9481-d6b2b8ba6530"
      },
      "source": [
        "model.predict(test_data)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 210, 34) for input KerasTensor(type_spec=TensorSpec(shape=(None, 210, 34), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 34).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9800582 ],\n",
              "       [0.9688581 ],\n",
              "       [0.98924065],\n",
              "       [0.98528486],\n",
              "       [0.59637094],\n",
              "       [0.5267546 ],\n",
              "       [0.84644735],\n",
              "       [0.99434304],\n",
              "       [0.97139513],\n",
              "       [0.98336107],\n",
              "       [0.7952347 ],\n",
              "       [0.85050035],\n",
              "       [0.97621644],\n",
              "       [0.9865742 ],\n",
              "       [0.7742679 ],\n",
              "       [0.72502166],\n",
              "       [0.98767966],\n",
              "       [0.99050176],\n",
              "       [0.9954644 ],\n",
              "       [0.9871192 ],\n",
              "       [0.99100626],\n",
              "       [0.98257947],\n",
              "       [0.9979896 ],\n",
              "       [0.9979078 ],\n",
              "       [0.99734485],\n",
              "       [0.86032546],\n",
              "       [0.5744484 ],\n",
              "       [0.9938934 ],\n",
              "       [0.98895395],\n",
              "       [0.99224496],\n",
              "       [0.9923947 ],\n",
              "       [0.9950237 ],\n",
              "       [0.9985142 ],\n",
              "       [0.99726313],\n",
              "       [0.9889569 ],\n",
              "       [0.99394006],\n",
              "       [0.996465  ],\n",
              "       [0.9496547 ],\n",
              "       [0.9878503 ],\n",
              "       [0.9970327 ],\n",
              "       [0.9987037 ],\n",
              "       [0.99744534],\n",
              "       [0.99748963],\n",
              "       [0.6810025 ],\n",
              "       [0.99569786],\n",
              "       [0.9965646 ],\n",
              "       [0.9975976 ],\n",
              "       [0.9853852 ],\n",
              "       [0.946239  ],\n",
              "       [0.99827045],\n",
              "       [0.99791384],\n",
              "       [0.9956567 ],\n",
              "       [0.99447376],\n",
              "       [0.99897504],\n",
              "       [0.9988797 ],\n",
              "       [0.99914825],\n",
              "       [0.99593484],\n",
              "       [0.9979507 ],\n",
              "       [0.91855025],\n",
              "       [0.9878292 ],\n",
              "       [0.26951897],\n",
              "       [0.9988595 ],\n",
              "       [0.9941019 ],\n",
              "       [0.7252415 ],\n",
              "       [0.98961985],\n",
              "       [0.7517861 ],\n",
              "       [0.9968082 ],\n",
              "       [0.99869525],\n",
              "       [0.9985995 ],\n",
              "       [0.996459  ],\n",
              "       [0.9939015 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs55McNwTq05"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}